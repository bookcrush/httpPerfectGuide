# HTTP

## 9.5 로봇 에티켓 
- 1. 신원 식별
  - 로봇의 신원을 밝히라: User-Agent 를 이용하여 웹 서버에게 로봇의 이름을 밝혀라
  - 기계의 신원을 밝혀라: DNS 엔트리를 가진 기계에서 실행된다는 것을 확실히 해서, 웹 사이트가 로봇의 IP 주소를 호스트 명을 통해 역방향 DNS 를 할 수 있도록 해라
  - 연락처를 밝혀라: HTTP 폼 필드를 사용해서 연락할 수 있는 이메일 주소를 제공하라
- 2. 동작 
  - 긴장하라: 로봇이 노련해지기 전까지는 운영자들을 고용해서 감시하라
  - 대비하라: 로봇이 여행을 떠나기전에 조직에 사실을 알려둬라
  - 감시와 로그: 로봇이 정상적으로 동작하는지 진행상황을 추적하고 기본적인 검사가 가능하도록 진단과 로깅 기능을 풍부하게 갖춰야한다.
  - 배우고 조정하라: 크롤링 할 때마다 새로운 것을 배우게 된다. 로봇을 조정하고 개선하라
- 3. 스스로를 제한하라
  - URL 을 필터링하라: 이해할 수 없거나 관심 없는 데이터를 참조하고 있다면 무시하는 것이 좋다.
  - 동적 URL 을 필터링하라: 보통 로봇은 동적인 게이트웨이로부터의 콘텐츠를 크롤링할 필요가 없다.
  - Accept 관련 헤더로 필터링: HTTP accept 관련 헤더들을 이용하여 콘텐츠를 이해할 수 있는지 말해주어야한다.
  - robots.txt 에 따르라: 방문 웹 사이트의 robots.txt 를 따라야한다.
  - 스스로를 억제하라: 한 사이트에 총 접근 횟수를 제한해야한다.
- 4. 루프와 중복을 견뎌내기, 그리고 그 외의 문제들
  - 모든 응답 코드 다루기: 모든 리다이렉트와 에러를 포함한 모든 HTTP 상태 코드를 다룰 수 있도록 준비되어 있어야한다.
  - URL 정규화하기: 모든 URL 을 표준화된 형식으로 변경하여 중복된 URL 을 제거하라 
  - 적극적으로 순환 피하기: 순환을 감지하고 피하기위해 노력하라 
  - 함정을 감시하라: 의도적이고 악의적인 순환을 피하기위해 함정을 감시하라
  - 블랙리스트를 관리하라: 함정, 깨진 사이트등을 블랙리스트로 추가하고 다시는 방문하지 않도록 해라 
- 5. 확장성
  - 대역폭 이해하기: 얼마나 많은 네트워크 대역폭이 사용 가능한지, 요구되는 시간에 로봇 작업을 끝마치는데 얼마나 필요할지 이해하라.
  - 시간 이해하기: 작업을 끝내는데 얼마나 많은 시간이 필요한지 이해하고, 소요된 시간이 추정한 것과 맞는지 간단히 검사해보라 
  - 분할 정복: 대규모 크롤링을 하는 상황에서는 멀티프로세서 서버든 서로 협력하는 여러 개의 작은 컴퓨터등 하드웨어들이 더 필요할 수 있다.
- 6. 신뢰성
  - 철저하게 테스트하라: 풀어놓기전 내부에서 철저하게 테스트하라
  - 체크포인트: 체크포인트/재시작 기능을 처음부터 설계하라 
  - 실패에 대한 유연성: 실패에 대비하여 로못을 실패가 발생했을 때도 계속 동작할 수 있도록 설계하라 
- 7. 소통
  - 준비하라: 로봇에 대한 정책 안내 페이지를 만들고 robots.txt 를 만드는 법에 대한 설명도 포함하라
  - 이해하라: 로봇 차단 규칙 표준에 대해 설명하고, 그래도 만족하지 못한다면 블랙리스트에 추가하라
  - 즉각 대응하라: 불만을 갖게되는 요소에 대해서 즉각 대응하라 
  
## 9.6 검색엔진

웹 로봇을 가장 광범위하게 사용하는 것은 인터넷 검색엔진이다. 
웹 크롤러들은 먹이를 주듯 검색엔진에게 웹에 존재하는 문서들을 가져다 주어서, 검색엔진이 어떤 문서에 어떤 단어들이 존재하는지에 대한 색인을 생성할 수 있게 한다.

### 9.6.1 넓게 생각하라 

초창기에 검색엔진은 단순한 데이터베이스였다. 급격히 웹이 성장하면서 수십억개의 페이지에 접근을 해야하니 단순한 데이터베이스 형식으로는 동작이 어려워졌다.

### 9.6.2 현대적인 검색엔진의 아키텍쳐

검색엔진들은 가지고 있는 웹페이지들에 대해 '풀 텍스트 색인'이라고 하는 복잡한 로컬 데이터베이스를 생성한다.

검색엔진 크롤러들은 웹페이지를 수집 -> 풀텍스트 색인 추가한다. 사용자들은 핫봇이나 구글 같은 웹 검색 게이트웨이를 통해 풀 텍스트 색인에 대한 질의를 보낸다.

### 9.6.3 풀 텍스트 색인 

풀 텍스트 색인은 단어 하나를 입력받아 그 단어를 포함하고 있는 문서를 즉각 알려줄 수 있는 데이터베이스이다.
이 문서들은 색인이 생성된 후에는 검색할 필요가 없다.

### 9.6.4 질의 보내기 

HTML 폼을 사용자가 채우고 브라우저가 폼을 GET / POST 요청을 이용해서 게이트웨이로 보낸다
게이트웨이는 검색 질의를 추출하고 웹 UI 질의를 풀텍스트 색인을 검색할 때 사용되는 표현식으로 변환한다.

### 9.6.5 검색 결괄릊 얼려하고 보여주기

검색엔진은 문서들이 주어진 단어와 가장관련이 많은 순서대로 결과 문서에 나타날 수 있도록 문서들 간의 순서를 알 필요가 있다.
이것은 관련도 랭킹 알고리즘이라 불리며, 검색 결과의 목록에 점수를 매기고 정렬하는 과정이다.
웹 크롤링하는 과정에서 수집된 통계 데이터를 실제로 사용한다.

### 9.6.6 스푸핑 

웹 사이트를 찾을 때 검색 결과의 순서는 중요하다.
웹 마스터에게는 자신이 만든 사이트가 그 자신을 가장 잘 설명하는 단어로 검색한 결과의 상단에 노출되도록 만들 동기가 충분하다.

많은 페이지들이 특정 단어에 대한 가짜 페이지를 생성하거나 검색엔진의 관련도 알고리즘을 잘 속일 수 있는 게이트웨이를 만들어 사용한다.

## HTTP/2.0

## 10.1 HTTP/2.0의 등장 배경

HTTP/1.0 의 메시지 포맷은 구현의 단순성과 접근성에 주안점을 두고 최적화되었다.
그러다 보니 성능은 어느 정도 희생시키지 않을 수 없었다. 커넥션 하나를 통해 요청 하나를 보내고 그에 대해 응답 하나만을 받는 HTTP 의 
메시지 교환 방식은 단순하지만 응답을 받아야만 다음 요청을 보낼 수 있기 때문에 회전 지연을 피할 수 없었다.

## 10.2 개요 

HTTP/2.0 은 서버와 클라이언트 사이의 TCP 커넥션 위에서 동작한다. 이때 TCP 커넥션을 초기화하는 것은 클라이언트다.
프레임들에 담긴 요청과 응답은 스트림을 통해 보내진다. 한 개의 스트림이 한쌍의 요청과 응답을 처리한다.
하나의 커넥션 위에 여러 개의 스트림이 동시에 만들어질 수 있으므로, 여러 개의 요청과 응답을 동시에 처리하는 것이 가능하다.

기존 애플리케이션들과 호환성을 유지하기 위해 요청과 응답 메시지의 의미를 HTTP/1.0 과 같도록 유지하고있다.

## 10.3 HTTP/1.1 과의 차이점

### 10.3.1 프레임

모든 메시지는 프레임에 담겨 전송된다. 프레임은 8바이트 크기의 헤더로 시작하며 최대 16383 바이트 크기의 페이로드가 온다.

- R: 예약된 2비트 필드, 값의 의미가 정의되어 있지 않으며, 0 이어야한다. 받는 쪽에서는 이 값을 무시한다.
- 길이: 페이로드의 길이를 나타내는 14비트 무부호 정수, 프레임 헤더는 포함되지 않는다.
- 종류: 프레임의 종류
- 플래그: 8 비트 플래그, 플래그 값의 의미는 프레임의 종류에 따라 다르다 
- R: 예약된 1 비트 필드, 첫번째 R 과 같다.
- 스트림 식별자: 31비트 스트림 식별자, 특별히 0은 커넥션 전체와 연관된 프레임을 의미한다.

### 10.3.2 스트림과 멀티플렉싱

스트림은 커넥션을 통해 클라이언트와 서버 사이에서 교환되는 프레임들의 독립된 양방향 시퀀스다.
클라이언트는 스트림을 만들어 HTTP 요청을 보낸다. 요청을 받은 서버는 요청과 같은 스트림으로 응답을 보낸다. 스트림을 닫는다.

HTTP/2.0 은 여러 개의 스트림이 동시에 열릴 수 있다. 뿐만 아니라 스트림은 우선순위도 가질 수 있다.
모든 스트림은 31 비트의 무부호 정수로 된 고유한 식별자를 갖는다. 
서버와 클라이언트는 스트림을 상대방과 협상 없이 일방적으로 만든다. 
이는 스트림을 만들 때 협상을 위해 TCP 패킷은 주고받느라 시간을 낭비하지 않아도 됨을 의미한다.
커넥션에서 한번 사용한 스트림 식별자는 다시 사용할 수 없다.
WINDOW_UPDATE 프레임을 이용한 흐름 제어를 통해 스트림들이 서로 간섭해서 망가지는 것을 막아준다.

### 10.3.3 헤더 압축

HTTP/1.1 에서 헤더는 아무런 압축 없이 그대로 전송되었다. 요즘에는 웹페이지 하나를 보기 위해 수십에서 많으면 수백 번의 요청을 보내기 때문에, 헤더의 크기가 회전 지연과 대역폭 양쪽 모두에 실직적인 영향을 끼치게 되었다.
이를 개선하기 위해 HTTP/2.0 은 메시지의 헤더를 압축하여 전송한다.

### 10.3.4 서버 푸시

서버가 하나의 요청에 대해 응답으로 여러 개의 리소스를 보낼 수 있도록 해준다. 이 기능은 서버가 클라이언트에서 어떤 리소스를 요구할 것인지 미리 알 수 있는 상황에서 유리하다. 
리소스를 푸시하려는 서버는 먼저 클라이언트에게 자원을 푸시할 것임을 PUSH_PROMISE 프레임을 보내어 미리 알려주어야 한다. 클라이언트가 프레임을 받게 되면 해당 프레임의 스트림은 클라이언트 입장에서는 예약됨 상태가 된다. 

- 서버 푸시를 사용하기로 했더라도, 중간의 프락시가 서버로부터 받은 추가 리소스를 클라이언트에게 전달하기 않을 수 있다.
- 서버는 오직 안전하고, 캐시 가능하고, 본문을 포함하지 않은 요청에 대해서만 푸시를 할 수 있다.
- 푸시할 리소스는 클라이언트가 명시적으로 보낸 요청과 연관된 것이어야 한다.
- 클라이언트는 서버가 푸시한 리소스를 동일 출처 정책에 따라 검사해야한다.
- 서버 푸시를 끄고 싶다면 SETTINGS_ENABLE_PUSH 를 0 으로 설정한다.

## 10.4 알려진 보안 이슈 

### 10.4.1 중개자 캡슐화 공격

HTTP/2.0 메시지를 중간 프락시가 HTTP/1.1 메시지로 변환할 때 메시지의 의미가 변질될 가능성이 있다. 
HTTP/1.1 과 달리 2.0 은 헤더 필드의 이름과 값을 바이너리로 인코딩한다. 이는 HTTP/2.0 이 헤더 필드로 어떤 문자열이든 사용할 수 있게 해준다.
이는 정상적인 .0 요청이나 응답이, 불법적이거나 위조된 HTTP/1.1 메시지로 번역되는 것을 유발할 수 있다.

### 10.4.2 긴 커넥션 유지로 인한 개인정보 노출 우려 

HTTP/2.0 은 사용자가 요청을 보낼 때의 회전 지연을 줄이기 위해 클라이언트와 서버 사이의 커넥션을 오래 유지하는 것을 염두에 두고 있다.
이것은 개인 정보의 유출에 악용될 가능성이 있다. 어떤 사용자가 브라우저를 사용할 때, 그 사용자는 이전에 브라우저를 사용했던 사용자가 무엇을 했는지 알아낼 가능성도 있다.






